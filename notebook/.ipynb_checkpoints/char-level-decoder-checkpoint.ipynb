{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import variable_scope\n",
    "from tensorflow.contrib.framework.python.framework import checkpoint_utils\n",
    "\n",
    "import random\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define parameters of the program\n",
    "corpus_path = '../data/got_all_edited.txt'\n",
    "\n",
    "num_epoch = 30\n",
    "\n",
    "batch_size = 30\n",
    "num_steps = 60\n",
    "embedding_size = 100\n",
    "\n",
    "hidden_unit_size = 256\n",
    "vocabulary_size = 20000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "sample_length = 10\n",
    "\n",
    "STOP_TOKEN = '*STOP*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function to load and preprocess the text corpus then return list of chars\n",
    "def read_file(path):\n",
    "    with open(corpus_path) as f:\n",
    "        char_tokens = ['*STOP*']\n",
    "        text = f.read()\n",
    "        char_tokens.extend(text)\n",
    "        \n",
    "        for i in range(len(char_tokens)):\n",
    "            if char_tokens[i] == '\\n':\n",
    "                char_tokens[i] = STOP_TOKEN\n",
    "        \n",
    "        return char_tokens\n",
    "    \n",
    "def build_dataset(tokens):\n",
    "    counts = []\n",
    "    counts.extend(collections.Counter(tokens).most_common())\n",
    "    \n",
    "    dictionary = dict()\n",
    "    data = list()\n",
    "    \n",
    "    for token, _ in counts:\n",
    "        dictionary[token] = len(dictionary)\n",
    "        \n",
    "    for token in tokens:\n",
    "        data.append(dictionary[token])\n",
    "        \n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    \n",
    "    return data, dictionary, reverse_dictionary\n",
    "\n",
    "def generate_batch(dataset, batch_size, num_steps, offset=0):\n",
    "    assert offset + batch_size * num_steps < len(dataset)\n",
    "    \n",
    "    batch_context = np.ndarray((batch_size, num_steps), dtype=np.int32)\n",
    "    batch_target = np.ndarray((batch_size, num_steps), dtype=np.int32)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        batch_context[i] = dataset[offset : offset+num_steps]\n",
    "        batch_target[i] = dataset[offset+1 : offset+num_steps+1]\n",
    "        offset += num_steps\n",
    "        \n",
    "    return batch_context, batch_target, offset\n",
    "\n",
    "tokens = read_file(corpus_path)\n",
    "data, tokendict, tokendictreversed = build_dataset(tokens)\n",
    "\n",
    "vocabsize = len(tokendict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # setup input and labels placeholders\n",
    "    seed_inputs = tf.placeholder(tf.int32, shape=[1, None])\n",
    "    single_input = tf.placeholder(tf.int32, shape=[1])\n",
    "    prev_state_c = tf.placeholder(tf.float32, shape=[1, 256])\n",
    "    prev_state_h = tf.placeholder(tf.float32, shape=[1, 256])\n",
    "    prev_state = (prev_state_c, prev_state_h)\n",
    "    \n",
    "    bsize = tf.placeholder(tf.int32)\n",
    "    temperature = tf.placeholder(tf.float32)\n",
    "    \n",
    "    logits_weights = tf.Variable(tf.truncated_normal([hidden_unit_size, vocabsize], stddev=0.1), \n",
    "                                     name='Variable_1')\n",
    "    logits_biases = tf.Variable(tf.zeros([vocabsize]),\n",
    "                                   name='Variable_2')\n",
    "    \n",
    "    # instantiate embedding matrix\n",
    "    charvectors = tf.Variable(tf.random_normal([vocabsize, embedding_size]), name='Variable')\n",
    "    seedcharvectors = tf.nn.embedding_lookup(charvectors, seed_inputs)\n",
    "    \n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_unit_size, forget_bias=0.0, state_is_tuple=True)\n",
    "    init_state = rnn_cell.zero_state(bsize, tf.float32)\n",
    "    outs, seed_state = tf.nn.dynamic_rnn(rnn_cell, seedcharvectors, initial_state=init_state)\n",
    "    seed_output = seed_state.h\n",
    "    seed_logits = tf.matmul(seed_output, logits_weights) + logits_biases\n",
    "   \n",
    "    with tf.variable_scope(\"RNN\") as scope:\n",
    "        scope.reuse_variables()\n",
    "        current_input = tf.nn.embedding_lookup(charvectors, single_input)\n",
    "        current_output, current_state = rnn_cell(current_input, prev_state)\n",
    " \n",
    "        logits = tf.matmul(current_output, logits_weights) + logits_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_softmax(logits, temperature=1.0):\n",
    "    logits = logits / temperature\n",
    "    softmax = np.exp(logits) / np.sum(np.exp(logits))\n",
    "    r = random.random() # range: [0,1)\n",
    "    total = 0.0\n",
    "    for i in range(len(softmax)):\n",
    "        total += softmax[i]\n",
    "        if total > r:\n",
    "            return i\n",
    "    return len(softmax)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arya re which and seen that the warrior said, but both swords through him to the ears and through her sgots of beds and steel of the sea with by she paused as he should have to lurd do with a few away. \"I was an ellow the boy best of Starks. You’re no strengt and stranger swords make off and with them to war. The lionfood black part when he will be more than a preyer of it. Jon murded the Stone captively, he could not have been not like the name. The gate had towno had past her spit of the tree burned they were all between the white look.*STOP*\"She was a chance of House Tyrell had gone.\"*STOP*\"I stood lay by head. I have comes at marry him, and your father was a face. What do you this to be marry more than a grite with the First the three gold from galleys. The fish fleed to say. \"My lord,\" she could not be blood and rose and pits and bold. It is no cold down see their desperous tank they could not be saying to drink.*STOP*\"They say. It was will be a bird son he can watch the rest of a Ser Desmand. In his finger, —the crue, and he needle turned them, they preced his mouth of his horse, and he raved him a fine little grandful and hands cheeks as a hundred hand, it kept in the inn ones. They sent ever must misside her. \"Asha stood the could once. And his break cloaks of chains. You could not remember him down the Seven had been away. \"Stannis could not see my arms. \"He had been buy you, my knight and drew or a man of captainst Queron the old fever. When Renly was the cabous and the saddle girl from him in the wind brown as he nodded from the room why shadow of his cheeks. If he did not seem my stone, but it was the cransess. He would have as she was no bad,\" the swords did she knew the you have looked some sweet silver ring.\"*STOP*\"How may squire pits how me?\"*STOP*\"Your empty still look?\"*STOP*\"Many that he would have been forwers. \"Lord Merrynne to with the protections, me sace Ser Gregor the cold brothers, they were legs before him. \"We ate the direwolf have even done it.\"*STOP*\"The Maester Sensa’s men, but the on the day of the first of the river may abjeen for we prove your eyes.\"*STOP*\"The place of Deepheart of the Sisters that he had not like the Hound will do the word, and a far of it, and the Fool of the shadows apone himself with Golden dreaming for ears, not leave him to his and shut his head and fire from a foor of him she thought he all for him. They are bone the man and pointed his swords beneath the strangers, a spence to do as set to her. \"Why had been been men, and they had never been more I save the steps and face and covered from the Tamps they’d half a fool the voice knew he is true... and Godswood.\"*STOP*\"And this was fighting to be brothers and the others were red up in all her, when Stannis said in his posside, but then she could have known the ironbed. Garion told her had hidden pock. \"Boy is fields thought my gate is the Bale is company. She will see it in a hand. Cersei has been refull the small, so berieeding swords. Even will have been his honor. \"I will so much meant for the boy... the Mountain. You know. The same young simpers think may call him.\"*STOP*\"I don’t have remembered a woman says, \"and what dead better her blood, it was day.\" His too drew with the ragen and his blood had ever been the whole brothers. \"He wanted in the like. All they would not know the dead boy with the place. He did not be such to the king hot the bloody crowned beasts had not gave her knee. \"Just be in the Starks through the flames of his maushed fingers to battle for brothers.\"*STOP*\"Father had a grievice man’s servants crows. Maester Ryck, the deep was the godswood on the longs, the Wall was every dreams as well. You will don’t told I’ve come at the a threat them we have t been the walls am the Kingsload, —TURA, his sick flamper, but the other things was rained at the boy. He was remained this ready cousins, though he said on his beneath the captain was a blood of the Ford. A friends stayed his sword and a storm. He thought a save taken at the inborn woman still good at white who companyed. \"What forget a left, I may need to return to be part of the brothers had even seen the first said. The northmens give her? He pool at the cloik and one.*STOP*Bring Maester Aemon there were al her feet. The rwal finger had been droving the trueble scarred of headful of a crown st live at Qyrion told him to leave him. As the Twins were woman to get his parts and gimps.\"*STOP*\"When there’s it to a stone. I emprote with meriaks. The northman of a good stone is to have to take to m... there were bed.\"*STOP*Ser Brynden said. \"He was a line and like that. They take him. The queen could not fale with him little gape with the more changers of stiffly and stony,\" he said. \"No you have keep me this mad from Lord Kneel and Their Grace Isleemorn. I seen the children that more father that not hrose to his choice. \"Oh,\" she began the ground to get his sable cold. She did not was closed to make you some smell of the throat in fish from her lord. She was the brother and him a spot men\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    var_saver = tf.train.Saver(tf.trainable_variables())\n",
    "    path = 'checkpoints/char_rnn_langmodel.ckpt'\n",
    "    var_saver.restore(sess, path)\n",
    "    \n",
    "    initial = sess.run(init_state, feed_dict={bsize: 1})\n",
    "    \n",
    "    seed_string = [map(lambda x: tokendict[x], 'Arya ')]\n",
    "    \n",
    "    feed_dict = {seed_inputs: seed_string,\n",
    "                 bsize: 1, init_state: initial}\n",
    "    [seed_s, seed_l] = sess.run([seed_state, seed_logits], feed_dict=feed_dict)\n",
    "    \n",
    "    # iterate through the length of the sample:\n",
    "    samples = [] + seed_string[0]\n",
    "    current_s = seed_s\n",
    "    current_logits = seed_l\n",
    "    current_inp = sample_softmax(current_logits[0], temperature=0.8)\n",
    "    for i in range(5000):\n",
    "        feed_dict = {single_input: [current_inp], prev_state_c: current_s.c, prev_state_h: current_s.h}\n",
    "        [current_logits, current_s] = sess.run([logits, current_state], feed_dict=feed_dict)\n",
    "\n",
    "        current_inp = sample_softmax(current_logits[0], temperature=0.8)\n",
    "        samples.append(current_inp)\n",
    "        \n",
    "    print ''.join(map(lambda x: tokendictreversed[x], samples))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
