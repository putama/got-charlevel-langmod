{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character-level RNN Language Model written in Tensorflow.\n",
    "\n",
    "The purpose of this notebook is to demonstrate how we could build Recurrent Neural Network for character language modeling and train them on the George R.R. Martin's Game of Thrones novel series. We will show how this learned language model to able to generate sequences of character that constitute story text with similar style as the GoT's novel text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to load and preprocess the text corpus then return list of chars\n",
    "def read_file(path):\n",
    "    with open(corpus_path) as f:\n",
    "        char_tokens = ['*STOP*']\n",
    "        text = f.read()\n",
    "        char_tokens.extend(text)\n",
    "        \n",
    "        for i in range(len(char_tokens)):\n",
    "            if char_tokens[i] == '\\n':\n",
    "                char_tokens[i] = '*STOP*'\n",
    "        \n",
    "        return char_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_dataset(tokens):\n",
    "    counts = []\n",
    "    counts.extend(collections.Counter(tokens).most_common())\n",
    "    \n",
    "    dictionary = dict()\n",
    "    data = list()\n",
    "    \n",
    "    for token, _ in counts:\n",
    "        dictionary[token] = len(dictionary)\n",
    "        \n",
    "    for token in tokens:\n",
    "        data.append(dictionary[token])\n",
    "        \n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    \n",
    "    return data, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(dataset, batch_size, num_steps, offset=0):\n",
    "    assert offset + batch_size * num_steps < len(dataset)\n",
    "    \n",
    "    batch_context = np.ndarray((batch_size, num_steps), dtype=np.int32)\n",
    "    batch_target = np.ndarray((batch_size, num_steps), dtype=np.int32)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        batch_context[i] = dataset[offset : offset+num_steps]\n",
    "        batch_target[i] = dataset[offset+1 : offset+num_steps+1]\n",
    "        offset += num_steps\n",
    "        \n",
    "    return batch_context, batch_target, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define parameters of the program\n",
    "corpus_path = '../data/got_all_edited.txt'\n",
    "\n",
    "num_epoch = 30\n",
    "\n",
    "batch_size = 5\n",
    "num_steps = 60\n",
    "embedding_size = 100\n",
    "\n",
    "hidden_unit_size = 256\n",
    "vocabulary_size = 20000\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = read_file(corpus_path)\n",
    "data, tokendict, tokendictreversed = build_dataset(tokens)\n",
    "\n",
    "vocabsize = len(tokendict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*STOP*\"We should start back,\" Gared urged as the woods began to g --> \n",
      "\"We should start back,\" Gared urged as the woods began to gr\n",
      "----------\n",
      "row dark around them. \"The wildlings are dead.\"*STOP*\"Do the dead --> \n",
      "ow dark around them. \"The wildlings are dead.\"*STOP*\"Do the dead \n",
      "----------\n",
      " frighten you?\" Ser Waymar Royce asked with just the hint of --> \n",
      "frighten you?\" Ser Waymar Royce asked with just the hint of \n",
      "----------\n",
      " a smile.*STOP*Gared did not rise to the bait. He was an old man, --> \n",
      "a smile.*STOP*Gared did not rise to the bait. He was an old man, \n",
      "----------\n",
      " past fifty, and he had seen the lordlings come and go. \"Dea --> \n",
      "past fifty, and he had seen the lordlings come and go. \"Dead\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "train, label, _ = generate_batch(data, batch_size, num_steps)\n",
    "for batch_train, batch_label in zip(train, label):\n",
    "    print ''.join([tokendictreversed[token] for token in batch_train]) + ' --> '\n",
    "    print ''.join([tokendictreversed[word] for word in batch_label])\n",
    "    print '----------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open(corpus_path) as f:\n",
    "#     edited = []\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         x = line.replace('`',\"'\").replace('”','\"').replace(\"“\", '\"')\n",
    "#         if not x == '\\n':\n",
    "#             if x[len(x)-2].isalpha() or x[len(x)-2] == ',':\n",
    "#                 x = x.replace('\\n', ' ')\n",
    "#         edited.append(x)\n",
    "        \n",
    "# with open('../data/got_all_edited.txt', 'w') as f:\n",
    "#     f.write(''.join(edited))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
